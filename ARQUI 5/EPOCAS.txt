EPOCAS :
Epoch 1/400
735/735 [==============================] - 6s 7ms/step - loss: 6980.2080 - mae: 61.1754 - val_loss: 8494.6797 - val_mae: 70.3232 - lr: 0.0010
Epoch 2/400
735/735 [==============================] - 5s 7ms/step - loss: 2744.2588 - mae: 38.5996 - val_loss: 1866.7614 - val_mae: 31.0148 - lr: 0.0010
Epoch 3/400
735/735 [==============================] - 5s 7ms/step - loss: 2276.4128 - mae: 35.1102 - val_loss: 1856.7078 - val_mae: 31.8455 - lr: 0.0010
Epoch 4/400
735/735 [==============================] - 5s 7ms/step - loss: 1901.1548 - mae: 31.6666 - val_loss: 980.8475 - val_mae: 23.1386 - lr: 0.0010
Epoch 5/400
735/735 [==============================] - 5s 7ms/step - loss: 1924.0990 - mae: 31.6680 - val_loss: 1895.7428 - val_mae: 31.3831 - lr: 0.0010
Epoch 6/400
735/735 [==============================] - 5s 7ms/step - loss: 1945.2379 - mae: 31.8215 - val_loss: 1527.2133 - val_mae: 27.9404 - lr: 0.0010
Epoch 7/400
735/735 [==============================] - 5s 7ms/step - loss: 1588.2740 - mae: 28.7288 - val_loss: 1851.8107 - val_mae: 30.6409 - lr: 0.0010
Epoch 8/400
735/735 [==============================] - 5s 7ms/step - loss: 1589.1293 - mae: 28.5694 - val_loss: 3024.6304 - val_mae: 38.2335 - lr: 0.0010
Epoch 9/400
734/735 [============================>.] - ETA: 0s - loss: 1514.5902 - mae: 27.9732
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
735/735 [==============================] - 5s 7ms/step - loss: 1516.3644 - mae: 27.9812 - val_loss: 1422.3700 - val_mae: 25.9956 - lr: 0.0010
Epoch 10/400
735/735 [==============================] - 5s 7ms/step - loss: 1140.8584 - mae: 24.4111 - val_loss: 878.3159 - val_mae: 20.2650 - lr: 5.0000e-04
Epoch 11/400
735/735 [==============================] - 5s 7ms/step - loss: 1137.0179 - mae: 24.1059 - val_loss: 797.5615 - val_mae: 20.0541 - lr: 5.0000e-04
Epoch 12/400
735/735 [==============================] - 5s 7ms/step - loss: 1044.8510 - mae: 23.1123 - val_loss: 588.5011 - val_mae: 19.9694 - lr: 5.0000e-04
Epoch 13/400
735/735 [==============================] - 5s 7ms/step - loss: 950.0150 - mae: 22.0741 - val_loss: 831.2247 - val_mae: 22.3419 - lr: 5.0000e-04
Epoch 14/400
735/735 [==============================] - 5s 7ms/step - loss: 949.1685 - mae: 21.8985 - val_loss: 478.4120 - val_mae: 17.1689 - lr: 5.0000e-04
Epoch 15/400
735/735 [==============================] - 5s 7ms/step - loss: 909.3273 - mae: 21.5658 - val_loss: 616.9274 - val_mae: 18.1921 - lr: 5.0000e-04
Epoch 16/400
735/735 [==============================] - 5s 7ms/step - loss: 866.1083 - mae: 20.9627 - val_loss: 959.7359 - val_mae: 22.0758 - lr: 5.0000e-04
Epoch 17/400
735/735 [==============================] - 5s 7ms/step - loss: 910.7432 - mae: 21.3341 - val_loss: 742.8471 - val_mae: 20.1771 - lr: 5.0000e-04
Epoch 18/400
735/735 [==============================] - 5s 7ms/step - loss: 836.4927 - mae: 20.5812 - val_loss: 687.5864 - val_mae: 21.2612 - lr: 5.0000e-04
Epoch 19/400
733/735 [============================>.] - ETA: 0s - loss: 795.9702 - mae: 19.9844
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
735/735 [==============================] - 5s 7ms/step - loss: 797.7575 - mae: 19.9881 - val_loss: 591.1902 - val_mae: 20.3303 - lr: 5.0000e-04
Epoch 20/400
735/735 [==============================] - 5s 6ms/step - loss: 679.0341 - mae: 18.5066 - val_loss: 621.2764 - val_mae: 20.6541 - lr: 2.5000e-04
Epoch 21/400
735/735 [==============================] - 5s 6ms/step - loss: 664.6136 - mae: 18.1810 - val_loss: 499.9361 - val_mae: 18.5723 - lr: 2.5000e-04
Epoch 22/400
735/735 [==============================] - 5s 7ms/step - loss: 629.7581 - mae: 17.8129 - val_loss: 458.7863 - val_mae: 15.8220 - lr: 2.5000e-04
Epoch 23/400
735/735 [==============================] - 5s 7ms/step - loss: 649.3038 - mae: 17.9928 - val_loss: 787.0788 - val_mae: 20.8877 - lr: 2.5000e-04
Epoch 24/400
735/735 [==============================] - 5s 7ms/step - loss: 621.6942 - mae: 17.5544 - val_loss: 404.2501 - val_mae: 16.1668 - lr: 2.5000e-04
Epoch 25/400
735/735 [==============================] - 5s 7ms/step - loss: 590.3905 - mae: 17.1332 - val_loss: 407.0424 - val_mae: 16.5139 - lr: 2.5000e-04
Epoch 26/400
735/735 [==============================] - 5s 6ms/step - loss: 599.2239 - mae: 17.3228 - val_loss: 653.3315 - val_mae: 21.2138 - lr: 2.5000e-04
Epoch 27/400
735/735 [==============================] - 5s 7ms/step - loss: 586.3522 - mae: 17.0875 - val_loss: 628.7392 - val_mae: 20.8182 - lr: 2.5000e-04
Epoch 28/400
735/735 [==============================] - 5s 7ms/step - loss: 605.0171 - mae: 17.3000 - val_loss: 816.5681 - val_mae: 20.9980 - lr: 2.5000e-04
Epoch 29/400
729/735 [============================>.] - ETA: 0s - loss: 581.9932 - mae: 16.9528
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
735/735 [==============================] - 5s 7ms/step - loss: 580.8226 - mae: 16.9462 - val_loss: 555.7847 - val_mae: 18.5081 - lr: 2.5000e-04
Epoch 30/400
735/735 [==============================] - 5s 7ms/step - loss: 515.2777 - mae: 16.0293 - val_loss: 639.3940 - val_mae: 21.6769 - lr: 1.2500e-04
Epoch 31/400
735/735 [==============================] - 5s 7ms/step - loss: 497.7899 - mae: 15.7791 - val_loss: 388.5680 - val_mae: 16.4111 - lr: 1.2500e-04
Epoch 32/400
735/735 [==============================] - 5s 7ms/step - loss: 488.7717 - mae: 15.6422 - val_loss: 490.0492 - val_mae: 18.0508 - lr: 1.2500e-04
Epoch 33/400
735/735 [==============================] - 5s 6ms/step - loss: 492.6708 - mae: 15.6783 - val_loss: 385.9683 - val_mae: 16.4066 - lr: 1.2500e-04
Epoch 34/400
735/735 [==============================] - 5s 6ms/step - loss: 481.5800 - mae: 15.5053 - val_loss: 599.1686 - val_mae: 19.9192 - lr: 1.2500e-04
Epoch 35/400
735/735 [==============================] - 5s 6ms/step - loss: 483.8217 - mae: 15.5402 - val_loss: 555.1817 - val_mae: 19.1040 - lr: 1.2500e-04
Epoch 36/400
735/735 [==============================] - 5s 7ms/step - loss: 484.0790 - mae: 15.5700 - val_loss: 409.0574 - val_mae: 16.5594 - lr: 1.2500e-04
Epoch 37/400
735/735 [==============================] - 5s 6ms/step - loss: 448.7618 - mae: 15.0600 - val_loss: 319.4277 - val_mae: 14.7750 - lr: 1.2500e-04
Epoch 38/400
735/735 [==============================] - 5s 7ms/step - loss: 461.4729 - mae: 15.2031 - val_loss: 421.3069 - val_mae: 17.5101 - lr: 1.2500e-04
Epoch 39/400
735/735 [==============================] - 5s 6ms/step - loss: 458.6444 - mae: 15.1091 - val_loss: 320.6631 - val_mae: 14.8560 - lr: 1.2500e-04
Epoch 40/400
735/735 [==============================] - 5s 7ms/step - loss: 466.2087 - mae: 15.1070 - val_loss: 347.4196 - val_mae: 15.6460 - lr: 1.2500e-04
Epoch 41/400
735/735 [==============================] - 5s 6ms/step - loss: 443.5459 - mae: 14.8675 - val_loss: 398.3782 - val_mae: 16.8183 - lr: 1.2500e-04
Epoch 42/400
730/735 [============================>.] - ETA: 0s - loss: 464.4212 - mae: 15.0455
Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
735/735 [==============================] - 5s 7ms/step - loss: 464.0111 - mae: 15.0433 - val_loss: 422.4627 - val_mae: 17.0927 - lr: 1.2500e-04
Epoch 43/400
735/735 [==============================] - 5s 6ms/step - loss: 424.4761 - mae: 14.5231 - val_loss: 352.9735 - val_mae: 15.6345 - lr: 6.2500e-05
Epoch 44/400
735/735 [==============================] - 5s 7ms/step - loss: 415.8967 - mae: 14.4739 - val_loss: 446.7091 - val_mae: 18.0628 - lr: 6.2500e-05
Epoch 45/400
735/735 [==============================] - 5s 7ms/step - loss: 420.2277 - mae: 14.4325 - val_loss: 430.6216 - val_mae: 17.7161 - lr: 6.2500e-05
Epoch 46/400
735/735 [==============================] - 5s 6ms/step - loss: 417.4092 - mae: 14.4447 - val_loss: 346.7968 - val_mae: 15.5556 - lr: 6.2500e-05
Epoch 47/400
731/735 [============================>.] - ETA: 0s - loss: 430.6805 - mae: 14.5478
Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
735/735 [==============================] - 5s 6ms/step - loss: 430.1688 - mae: 14.5424 - val_loss: 378.4756 - val_mae: 16.6893 - lr: 6.2500e-05