
Epoch 1/400
1568/1568 [==============================] - 14s 8ms/step - loss: 6848.2925 - mae: 63.9850 - val_loss: 4540.9399 - val_mae: 52.3126 - lr: 0.0010
Epoch 2/400
1568/1568 [==============================] - 11s 7ms/step - loss: 2907.6731 - mae: 39.4149 - val_loss: 1099.4427 - val_mae: 24.2193 - lr: 0.0010
Epoch 3/400
1568/1568 [==============================] - 11s 7ms/step - loss: 965.7745 - mae: 21.5892 - val_loss: 1257.9384 - val_mae: 26.3392 - lr: 0.0010
Epoch 4/400
1568/1568 [==============================] - 11s 7ms/step - loss: 711.1165 - mae: 18.3948 - val_loss: 1294.8241 - val_mae: 25.6979 - lr: 0.0010
Epoch 5/400
1568/1568 [==============================] - 12s 8ms/step - loss: 611.4797 - mae: 16.6953 - val_loss: 388.7109 - val_mae: 13.0844 - lr: 0.0010
Epoch 6/400
1568/1568 [==============================] - 12s 8ms/step - loss: 532.2744 - mae: 15.4319 - val_loss: 402.7325 - val_mae: 13.9063 - lr: 0.0010
Epoch 7/400
1568/1568 [==============================] - 13s 8ms/step - loss: 458.4997 - mae: 14.2947 - val_loss: 520.8919 - val_mae: 16.4746 - lr: 0.0010
Epoch 8/400
1568/1568 [==============================] - 12s 8ms/step - loss: 443.9361 - mae: 13.9376 - val_loss: 498.0911 - val_mae: 16.6115 - lr: 0.0010
Epoch 9/400
1568/1568 [==============================] - 11s 7ms/step - loss: 378.0598 - mae: 12.9061 - val_loss: 371.8704 - val_mae: 12.2411 - lr: 0.0010
Epoch 10/400
1568/1568 [==============================] - 12s 8ms/step - loss: 383.1570 - mae: 12.9314 - val_loss: 312.5750 - val_mae: 11.4167 - lr: 0.0010
Epoch 11/400
1568/1568 [==============================] - 12s 7ms/step - loss: 340.8729 - mae: 12.2171 - val_loss: 622.2851 - val_mae: 18.8438 - lr: 0.0010
Epoch 12/400
1568/1568 [==============================] - 12s 8ms/step - loss: 297.9890 - mae: 11.3644 - val_loss: 298.4321 - val_mae: 10.9792 - lr: 0.0010
Epoch 13/400
1568/1568 [==============================] - 11s 7ms/step - loss: 299.8985 - mae: 11.3734 - val_loss: 480.0747 - val_mae: 15.7753 - lr: 0.0010
Epoch 14/400
1568/1568 [==============================] - 12s 8ms/step - loss: 247.7321 - mae: 10.2304 - val_loss: 310.8405 - val_mae: 11.0420 - lr: 0.0010
Epoch 15/400
1568/1568 [==============================] - 12s 8ms/step - loss: 207.0476 - mae: 9.2014 - val_loss: 168.0154 - val_mae: 8.4879 - lr: 0.0010
Epoch 16/400
1568/1568 [==============================] - 12s 8ms/step - loss: 214.6021 - mae: 9.2062 - val_loss: 180.6953 - val_mae: 8.2332 - lr: 0.0010
Epoch 17/400
1568/1568 [==============================] - 10s 7ms/step - loss: 210.7465 - mae: 9.2347 - val_loss: 119.8214 - val_mae: 7.1483 - lr: 0.0010
Epoch 18/400
1568/1568 [==============================] - 13s 8ms/step - loss: 171.6864 - mae: 8.3210 - val_loss: 143.5146 - val_mae: 7.7589 - lr: 0.0010
Epoch 19/400
1568/1568 [==============================] - 11s 7ms/step - loss: 160.6111 - mae: 7.9566 - val_loss: 123.9808 - val_mae: 7.3517 - lr: 0.0010
Epoch 20/400
1568/1568 [==============================] - 12s 8ms/step - loss: 193.2854 - mae: 8.5126 - val_loss: 122.1528 - val_mae: 7.2913 - lr: 0.0010
Epoch 21/400
1568/1568 [==============================] - 12s 8ms/step - loss: 161.0388 - mae: 7.7422 - val_loss: 114.3778 - val_mae: 6.7643 - lr: 0.0010
Epoch 22/400
1568/1568 [==============================] - 13s 8ms/step - loss: 138.5229 - mae: 7.2254 - val_loss: 190.1992 - val_mae: 9.2088 - lr: 0.0010
Epoch 23/400
1568/1568 [==============================] - 11s 7ms/step - loss: 154.0280 - mae: 7.6401 - val_loss: 115.2526 - val_mae: 6.2672 - lr: 0.0010
Epoch 24/400
1568/1568 [==============================] - 11s 7ms/step - loss: 128.5244 - mae: 6.9167 - val_loss: 96.3468 - val_mae: 6.7157 - lr: 0.0010
Epoch 25/400
1568/1568 [==============================] - 10s 6ms/step - loss: 145.6331 - mae: 7.2504 - val_loss: 139.4123 - val_mae: 8.2172 - lr: 0.0010
Epoch 26/400
1568/1568 [==============================] - 12s 8ms/step - loss: 126.9276 - mae: 6.8767 - val_loss: 73.1694 - val_mae: 5.6154 - lr: 0.0010
Epoch 27/400
1568/1568 [==============================] - 12s 8ms/step - loss: 119.3457 - mae: 6.5891 - val_loss: 137.6954 - val_mae: 7.9536 - lr: 0.0010
Epoch 28/400
1568/1568 [==============================] - 10s 7ms/step - loss: 119.0287 - mae: 6.5870 - val_loss: 305.5937 - val_mae: 12.3031 - lr: 0.0010
Epoch 29/400
1568/1568 [==============================] - 11s 7ms/step - loss: 102.7384 - mae: 6.2587 - val_loss: 60.9596 - val_mae: 5.3106 - lr: 0.0010
Epoch 30/400
1568/1568 [==============================] - 12s 7ms/step - loss: 130.5960 - mae: 6.9157 - val_loss: 69.5493 - val_mae: 5.2115 - lr: 0.0010
Epoch 31/400
1568/1568 [==============================] - 11s 7ms/step - loss: 103.5107 - mae: 6.1475 - val_loss: 61.1955 - val_mae: 5.3070 - lr: 0.0010
Epoch 32/400
1568/1568 [==============================] - 13s 9ms/step - loss: 96.1093 - mae: 5.9608 - val_loss: 74.5541 - val_mae: 4.9665 - lr: 0.0010
Epoch 33/400
1568/1568 [==============================] - 11s 7ms/step - loss: 118.6978 - mae: 6.5233 - val_loss: 154.0771 - val_mae: 8.4170 - lr: 0.0010
Epoch 34/400
1561/1568 [============================>.] - ETA: 0s - loss: 94.6638 - mae: 5.8371
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
1568/1568 [==============================] - 12s 7ms/step - loss: 94.7734 - mae: 5.8408 - val_loss: 112.9720 - val_mae: 7.4129 - lr: 0.0010
Epoch 35/400
1568/1568 [==============================] - 11s 7ms/step - loss: 42.5745 - mae: 3.9314 - val_loss: 32.3998 - val_mae: 3.4625 - lr: 5.0000e-04
Epoch 36/400
1568/1568 [==============================] - 12s 8ms/step - loss: 48.5101 - mae: 4.0619 - val_loss: 52.3197 - val_mae: 4.7913 - lr: 5.0000e-04
Epoch 37/400
1568/1568 [==============================] - 12s 8ms/step - loss: 39.0610 - mae: 3.8757 - val_loss: 31.7542 - val_mae: 3.6699 - lr: 5.0000e-04
Epoch 38/400
1568/1568 [==============================] - 12s 7ms/step - loss: 60.4305 - mae: 4.4789 - val_loss: 31.1514 - val_mae: 3.5394 - lr: 5.0000e-04
Epoch 39/400
1568/1568 [==============================] - 13s 8ms/step - loss: 38.7147 - mae: 3.6664 - val_loss: 26.4998 - val_mae: 3.2002 - lr: 5.0000e-04
Epoch 40/400
1568/1568 [==============================] - 11s 7ms/step - loss: 43.3002 - mae: 3.8389 - val_loss: 24.4659 - val_mae: 3.2000 - lr: 5.0000e-04
Epoch 41/400
1568/1568 [==============================] - 12s 7ms/step - loss: 27.7435 - mae: 3.3230 - val_loss: 27.0657 - val_mae: 3.1737 - lr: 5.0000e-04
Epoch 42/400
1568/1568 [==============================] - 12s 7ms/step - loss: 39.3570 - mae: 3.7895 - val_loss: 166.2181 - val_mae: 6.3436 - lr: 5.0000e-04
Epoch 43/400
1568/1568 [==============================] - 12s 7ms/step - loss: 33.4401 - mae: 3.4411 - val_loss: 59.5715 - val_mae: 5.8269 - lr: 5.0000e-04
Epoch 44/400
1568/1568 [==============================] - 11s 7ms/step - loss: 36.7101 - mae: 3.6728 - val_loss: 23.5026 - val_mae: 3.1233 - lr: 5.0000e-04
Epoch 45/400
1568/1568 [==============================] - 11s 7ms/step - loss: 29.4888 - mae: 3.3480 - val_loss: 31.6080 - val_mae: 3.5242 - lr: 5.0000e-04
Epoch 46/400
1568/1568 [==============================] - 11s 7ms/step - loss: 38.0601 - mae: 3.6435 - val_loss: 16.7146 - val_mae: 2.5090 - lr: 5.0000e-04
Epoch 47/400
1568/1568 [==============================] - 12s 7ms/step - loss: 28.2818 - mae: 3.1278 - val_loss: 19.7138 - val_mae: 2.7647 - lr: 5.0000e-04
Epoch 48/400
1568/1568 [==============================] - 11s 7ms/step - loss: 43.0322 - mae: 3.7034 - val_loss: 54.7500 - val_mae: 4.9840 - lr: 5.0000e-04
Epoch 49/400
1568/1568 [==============================] - 12s 8ms/step - loss: 39.7216 - mae: 3.3672 - val_loss: 19.7886 - val_mae: 2.9208 - lr: 5.0000e-04
Epoch 50/400
1568/1568 [==============================] - 10s 7ms/step - loss: 39.5649 - mae: 3.6023 - val_loss: 33.1364 - val_mae: 3.2704 - lr: 5.0000e-04
Epoch 51/400
1566/1568 [============================>.] - ETA: 0s - loss: 32.2322 - mae: 3.3494
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
1568/1568 [==============================] - 12s 8ms/step - loss: 32.2205 - mae: 3.3500 - val_loss: 36.2246 - val_mae: 3.9701 - lr: 5.0000e-04
Epoch 52/400
1568/1568 [==============================] - 11s 7ms/step - loss: 14.7365 - mae: 2.3619 - val_loss: 16.5283 - val_mae: 2.6847 - lr: 2.5000e-04
Epoch 53/400
1568/1568 [==============================] - 11s 7ms/step - loss: 16.3807 - mae: 2.4307 - val_loss: 13.7514 - val_mae: 2.2399 - lr: 2.5000e-04
Epoch 54/400
1568/1568 [==============================] - 10s 7ms/step - loss: 15.6652 - mae: 2.4044 - val_loss: 24.6403 - val_mae: 2.9470 - lr: 2.5000e-04
Epoch 55/400
1568/1568 [==============================] - 12s 7ms/step - loss: 16.6006 - mae: 2.4545 - val_loss: 12.5120 - val_mae: 2.1260 - lr: 2.5000e-04
Epoch 56/400
1568/1568 [==============================] - 10s 6ms/step - loss: 19.6548 - mae: 2.4792 - val_loss: 11.6377 - val_mae: 2.1100 - lr: 2.5000e-04
Epoch 57/400
1568/1568 [==============================] - 12s 8ms/step - loss: 13.7292 - mae: 2.2785 - val_loss: 12.4575 - val_mae: 2.1527 - lr: 2.5000e-04
Epoch 58/400
1568/1568 [==============================] - 12s 7ms/step - loss: 13.7014 - mae: 2.3308 - val_loss: 16.2144 - val_mae: 2.2404 - lr: 2.5000e-04
Epoch 59/400
1568/1568 [==============================] - 10s 7ms/step - loss: 20.9276 - mae: 2.6067 - val_loss: 14.8867 - val_mae: 2.4377 - lr: 2.5000e-04
Epoch 60/400
1568/1568 [==============================] - 11s 7ms/step - loss: 12.9526 - mae: 2.1401 - val_loss: 10.5794 - val_mae: 1.8429 - lr: 2.5000e-04
Epoch 61/400
1568/1568 [==============================] - 11s 7ms/step - loss: 14.4969 - mae: 2.1886 - val_loss: 11.8038 - val_mae: 2.0309 - lr: 2.5000e-04
Epoch 62/400
1568/1568 [==============================] - 11s 7ms/step - loss: 11.6383 - mae: 2.1151 - val_loss: 12.6574 - val_mae: 2.3028 - lr: 2.5000e-04
Epoch 63/400
1568/1568 [==============================] - 12s 8ms/step - loss: 17.3098 - mae: 2.4165 - val_loss: 11.1686 - val_mae: 1.9922 - lr: 2.5000e-04
Epoch 64/400
1568/1568 [==============================] - 11s 7ms/step - loss: 12.6955 - mae: 2.1562 - val_loss: 11.9959 - val_mae: 2.1925 - lr: 2.5000e-04
Epoch 65/400
1568/1568 [==============================] - 13s 8ms/step - loss: 16.9704 - mae: 2.4261 - val_loss: 9.9584 - val_mae: 1.9188 - lr: 2.5000e-04
Epoch 66/400
1568/1568 [==============================] - 12s 7ms/step - loss: 11.0165 - mae: 2.0184 - val_loss: 26.6761 - val_mae: 3.3941 - lr: 2.5000e-04
Epoch 67/400
1568/1568 [==============================] - 12s 7ms/step - loss: 11.3426 - mae: 2.0756 - val_loss: 10.5329 - val_mae: 2.0175 - lr: 2.5000e-04
Epoch 68/400
1568/1568 [==============================] - 11s 7ms/step - loss: 18.7831 - mae: 2.4295 - val_loss: 9.6536 - val_mae: 1.9408 - lr: 2.5000e-04
Epoch 69/400
1568/1568 [==============================] - 11s 7ms/step - loss: 11.3902 - mae: 2.0273 - val_loss: 12.3225 - val_mae: 2.2172 - lr: 2.5000e-04
Epoch 70/400
1568/1568 [==============================] - 10s 7ms/step - loss: 10.4056 - mae: 1.9965 - val_loss: 12.1229 - val_mae: 2.1784 - lr: 2.5000e-04
Epoch 71/400
1568/1568 [==============================] - 11s 7ms/step - loss: 14.9755 - mae: 2.2777 - val_loss: 9.9021 - val_mae: 1.7821 - lr: 2.5000e-04
Epoch 72/400
1568/1568 [==============================] - 11s 7ms/step - loss: 17.3018 - mae: 2.2761 - val_loss: 19.4077 - val_mae: 2.9841 - lr: 2.5000e-04
Epoch 73/400
1561/1568 [============================>.] - ETA: 0s - loss: 11.2705 - mae: 2.0078
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
1568/1568 [==============================] - 11s 7ms/step - loss: 11.7085 - mae: 2.0254 - val_loss: 53.9731 - val_mae: 4.7423 - lr: 2.5000e-04
Epoch 74/400
1568/1568 [==============================] - 11s 7ms/step - loss: 8.7255 - mae: 1.7375 - val_loss: 8.9192 - val_mae: 1.6952 - lr: 1.2500e-04
Epoch 75/400
1568/1568 [==============================] - 12s 8ms/step - loss: 7.9556 - mae: 1.6919 - val_loss: 11.7183 - val_mae: 2.0923 - lr: 1.2500e-04
Epoch 76/400
1568/1568 [==============================] - 10s 7ms/step - loss: 8.5789 - mae: 1.7656 - val_loss: 8.3315 - val_mae: 1.6107 - lr: 1.2500e-04
Epoch 77/400
1568/1568 [==============================] - 11s 7ms/step - loss: 8.4545 - mae: 1.6984 - val_loss: 8.4704 - val_mae: 1.6693 - lr: 1.2500e-04
Epoch 78/400
1568/1568 [==============================] - 12s 8ms/step - loss: 8.8775 - mae: 1.7424 - val_loss: 9.8768 - val_mae: 1.8551 - lr: 1.2500e-04
Epoch 79/400
1568/1568 [==============================] - 12s 8ms/step - loss: 7.9308 - mae: 1.6646 - val_loss: 8.7894 - val_mae: 1.6607 - lr: 1.2500e-04
Epoch 80/400
1568/1568 [==============================] - 11s 7ms/step - loss: 7.6282 - mae: 1.6331 - val_loss: 8.3072 - val_mae: 1.7283 - lr: 1.2500e-04
Epoch 81/400
1568/1568 [==============================] - 12s 8ms/step - loss: 8.4482 - mae: 1.7028 - val_loss: 8.4891 - val_mae: 1.7409 - lr: 1.2500e-04
Epoch 82/400
1568/1568 [==============================] - 12s 8ms/step - loss: 7.3403 - mae: 1.6116 - val_loss: 7.1348 - val_mae: 1.4752 - lr: 1.2500e-04
Epoch 83/400
1568/1568 [==============================] - 10s 7ms/step - loss: 7.9050 - mae: 1.6385 - val_loss: 14.2358 - val_mae: 2.4239 - lr: 1.2500e-04
Epoch 84/400
1568/1568 [==============================] - 12s 8ms/step - loss: 7.6068 - mae: 1.6436 - val_loss: 10.0477 - val_mae: 1.8880 - lr: 1.2500e-04
Epoch 85/400
1568/1568 [==============================] - 10s 7ms/step - loss: 8.2396 - mae: 1.6913 - val_loss: 7.0632 - val_mae: 1.4922 - lr: 1.2500e-04
Epoch 86/400
1568/1568 [==============================] - 11s 7ms/step - loss: 7.4227 - mae: 1.6219 - val_loss: 9.4353 - val_mae: 1.6302 - lr: 1.2500e-04
Epoch 87/400
1568/1568 [==============================] - 10s 7ms/step - loss: 9.0961 - mae: 1.7122 - val_loss: 7.2778 - val_mae: 1.5292 - lr: 1.2500e-04
Epoch 88/400
1568/1568 [==============================] - 11s 7ms/step - loss: 7.7341 - mae: 1.6131 - val_loss: 7.9148 - val_mae: 1.5765 - lr: 1.2500e-04
Epoch 89/400
1568/1568 [==============================] - 11s 7ms/step - loss: 7.3408 - mae: 1.5999 - val_loss: 10.6599 - val_mae: 1.8931 - lr: 1.2500e-04
Epoch 90/400
1566/1568 [============================>.] - ETA: 0s - loss: 7.3131 - mae: 1.6021
Epoch 90: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
1568/1568 [==============================] - 12s 8ms/step - loss: 7.3114 - mae: 1.6023 - val_loss: 7.5662 - val_mae: 1.5759 - lr: 1.2500e-04
Epoch 91/400
1568/1568 [==============================] - 11s 7ms/step - loss: 6.1593 - mae: 1.4073 - val_loss: 7.2046 - val_mae: 1.5581 - lr: 6.2500e-05
Epoch 92/400
1568/1568 [==============================] - 13s 8ms/step - loss: 6.1152 - mae: 1.4161 - val_loss: 7.6614 - val_mae: 1.6370 - lr: 6.2500e-05
Epoch 93/400
1568/1568 [==============================] - 13s 8ms/step - loss: 6.0289 - mae: 1.4182 - val_loss: 7.8887 - val_mae: 1.5825 - lr: 6.2500e-05
Epoch 94/400
1568/1568 [==============================] - 12s 8ms/step - loss: 6.1796 - mae: 1.4192 - val_loss: 7.7839 - val_mae: 1.5939 - lr: 6.2500e-05
Epoch 95/400
1568/1568 [==============================] - 11s 7ms/step - loss: 6.2049 - mae: 1.4152 - val_loss: 6.5768 - val_mae: 1.4534 - lr: 6.2500e-05
Epoch 96/400
1568/1568 [==============================] - 12s 7ms/step - loss: 6.0093 - mae: 1.3992 - val_loss: 6.9305 - val_mae: 1.4778 - lr: 6.2500e-05
Epoch 97/400
1568/1568 [==============================] - 12s 8ms/step - loss: 6.0142 - mae: 1.3932 - val_loss: 6.9153 - val_mae: 1.4727 - lr: 6.2500e-05
Epoch 98/400
1568/1568 [==============================] - 12s 8ms/step - loss: 6.0119 - mae: 1.3888 - val_loss: 6.3882 - val_mae: 1.3976 - lr: 6.2500e-05
Epoch 99/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.9659 - mae: 1.4090 - val_loss: 6.6226 - val_mae: 1.4565 - lr: 6.2500e-05
Epoch 100/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.8783 - mae: 1.3745 - val_loss: 6.4711 - val_mae: 1.3951 - lr: 6.2500e-05
Epoch 101/400
1568/1568 [==============================] - 10s 6ms/step - loss: 5.8312 - mae: 1.3814 - val_loss: 6.9248 - val_mae: 1.4483 - lr: 6.2500e-05
Epoch 102/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.9420 - mae: 1.3873 - val_loss: 6.2364 - val_mae: 1.3838 - lr: 6.2500e-05
Epoch 103/400
1568/1568 [==============================] - 10s 7ms/step - loss: 5.9286 - mae: 1.3811 - val_loss: 7.2566 - val_mae: 1.5403 - lr: 6.2500e-05
Epoch 104/400
1568/1568 [==============================] - 10s 6ms/step - loss: 5.7654 - mae: 1.3721 - val_loss: 6.9370 - val_mae: 1.5195 - lr: 6.2500e-05
Epoch 105/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.6279 - mae: 1.3561 - val_loss: 6.5823 - val_mae: 1.4219 - lr: 6.2500e-05
Epoch 106/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.7513 - mae: 1.3802 - val_loss: 8.5799 - val_mae: 1.7238 - lr: 6.2500e-05
Epoch 107/400
1566/1568 [============================>.] - ETA: 0s - loss: 5.8354 - mae: 1.3679
Epoch 107: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
1568/1568 [==============================] - 11s 7ms/step - loss: 5.8435 - mae: 1.3688 - val_loss: 7.8267 - val_mae: 1.6156 - lr: 6.2500e-05
Epoch 108/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.2559 - mae: 1.2626 - val_loss: 6.0728 - val_mae: 1.3282 - lr: 3.1250e-05
Epoch 109/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.0854 - mae: 1.2482 - val_loss: 5.8921 - val_mae: 1.2883 - lr: 3.1250e-05
Epoch 110/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.1287 - mae: 1.2627 - val_loss: 6.2840 - val_mae: 1.3413 - lr: 3.1250e-05
Epoch 111/400
1568/1568 [==============================] - 12s 8ms/step - loss: 5.0325 - mae: 1.2437 - val_loss: 6.4267 - val_mae: 1.3840 - lr: 3.1250e-05
Epoch 112/400
1568/1568 [==============================] - 11s 7ms/step - loss: 5.1022 - mae: 1.2578 - val_loss: 6.4364 - val_mae: 1.4562 - lr: 3.1250e-05
Epoch 113/400
1568/1568 [==============================] - 10s 6ms/step - loss: 5.1411 - mae: 1.2619 - val_loss: 5.9442 - val_mae: 1.2941 - lr: 3.1250e-05
Epoch 114/400
1567/1568 [============================>.] - ETA: 0s - loss: 5.0685 - mae: 1.2469
Epoch 114: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
1568/1568 [==============================] - 11s 7ms/step - loss: 5.0668 - mae: 1.2467 - val_loss: 6.0195 - val_mae: 1.3439 - lr: 3.1250e-05
Epoch 115/400
1568/1568 [==============================] - 9s 6ms/step - loss: 4.8381 - mae: 1.2024 - val_loss: 5.9047 - val_mae: 1.2669 - lr: 1.5625e-05
Epoch 116/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.8031 - mae: 1.1985 - val_loss: 5.9276 - val_mae: 1.2896 - lr: 1.5625e-05
Epoch 117/400
1568/1568 [==============================] - 12s 7ms/step - loss: 4.8166 - mae: 1.1993 - val_loss: 5.8199 - val_mae: 1.2790 - lr: 1.5625e-05
Epoch 118/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.8075 - mae: 1.1919 - val_loss: 5.9201 - val_mae: 1.2839 - lr: 1.5625e-05
Epoch 119/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.7491 - mae: 1.1917 - val_loss: 5.7996 - val_mae: 1.2617 - lr: 1.5625e-05
Epoch 120/400
1568/1568 [==============================] - 13s 8ms/step - loss: 4.7503 - mae: 1.1843 - val_loss: 6.0178 - val_mae: 1.3459 - lr: 1.5625e-05
Epoch 121/400
1568/1568 [==============================] - 10s 7ms/step - loss: 4.7471 - mae: 1.1882 - val_loss: 5.8139 - val_mae: 1.2920 - lr: 1.5625e-05
Epoch 122/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.7406 - mae: 1.1846 - val_loss: 5.6719 - val_mae: 1.2519 - lr: 1.5625e-05
Epoch 123/400
1568/1568 [==============================] - 10s 7ms/step - loss: 4.7640 - mae: 1.1871 - val_loss: 5.7361 - val_mae: 1.2831 - lr: 1.5625e-05
Epoch 124/400
1568/1568 [==============================] - 10s 7ms/step - loss: 4.7563 - mae: 1.1933 - val_loss: 6.0225 - val_mae: 1.2890 - lr: 1.5625e-05
Epoch 125/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.7419 - mae: 1.1797 - val_loss: 6.0261 - val_mae: 1.3140 - lr: 1.5625e-05
Epoch 126/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.7167 - mae: 1.1830 - val_loss: 5.9179 - val_mae: 1.3091 - lr: 1.5625e-05
Epoch 127/400
1567/1568 [============================>.] - ETA: 0s - loss: 4.7500 - mae: 1.1843
Epoch 127: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.
1568/1568 [==============================] - 11s 7ms/step - loss: 4.7482 - mae: 1.1841 - val_loss: 5.6972 - val_mae: 1.2552 - lr: 1.5625e-05
Epoch 128/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.6119 - mae: 1.1515 - val_loss: 5.7144 - val_mae: 1.2497 - lr: 7.8125e-06
Epoch 129/400
1568/1568 [==============================] - 12s 8ms/step - loss: 4.5706 - mae: 1.1534 - val_loss: 5.7782 - val_mae: 1.2566 - lr: 7.8125e-06
Epoch 130/400
1568/1568 [==============================] - 11s 7ms/step - loss: 4.6004 - mae: 1.1542 - val_loss: 5.7956 - val_mae: 1.2583 - lr: 7.8125e-06
Epoch 131/400
1568/1568 [==============================] - 10s 7ms/step - loss: 4.5781 - mae: 1.1507 - val_loss: 5.6988 - val_mae: 1.2414 - lr: 7.8125e-06
Epoch 132/400
1562/1568 [============================>.] - ETA: 0s - loss: 4.5097 - mae: 1.1517
Epoch 132: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.
1568/1568 [==============================] - 10s 7ms/step - loss: 4.5682 - mae: 1.1536 - val_loss: 5.7416 - val_mae: 1.2874 - lr: 7.8125e-06